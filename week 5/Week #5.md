# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил(а):
- Ежова Алисса Дмитриевна
- РИ-230931
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity

## Задание 1
## Найдите внутри C# скрипта “коэффициент корреляции ” и сделать выводы о том, как он влияет на обучение модели.
Коэфициентом коррелляции является значение, по которому можно сооттнести результаты агента в цикле обучение. В данном случае коэфициентом корреляции будет наибольшее расстояние между агентом и его целью. В исходном скрипте данное значение равно 1.42
От данного значения зависит скорость обучени. Например, если уменьшить данный коэфициент до 1, мы можем заметить что обучение действительно проходит медленнее, среднее вознагражение становиться меньше т.е агет реже достигает поставленную цель.
Если мы посмотрим на нашу сцену, то заметим, что поиск цели проходит гораздо дольше.
Если же мы наоборот увеличим наше значение жо 3, то значение среднего вознаграждения резко возрастет. Однако мы можем заметить, что на шарик может не достигать куба, но это все равно будет засчитанно.
Логирование при подстановке различных значений:
![1](https://github.com/user-attachments/assets/5fc084e7-32e0-4bfc-a855-fe91d969d195)
![2](https://github.com/user-attachments/assets/6fbc725f-0400-4ea9-871b-8df30062bf68)
![3](https://github.com/user-attachments/assets/2283c308-b161-4542-a2a0-dadb5173f4ee)

Я считаю, что коэфициент коррелляции в данном случае будет способствовать тому, чтобы агент стремился к своей цели и выискивал точку попадая, уменьшая среднее значение отклонений.

## Задание 2
###  Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров.
- Если попробовать изменить значение параметра, который отвечает за максимальное количество шагов при обучении, то процесс обучения завершиться в разы быстрее, но время поиска цели объектом становится больше из-за чего модель работает медленнее
- Если попробовать изменить значение параметра, который отвечает за колличество эмох обучения и уменьшить его, то общее время обучения уменьшиться, а среднее значения вознограждения увеличится. 
- Если попробовать изменить значение параметра batch_size и увеличить его, то время обучения будет уменьшаться

## Задание 3
###  Приведите примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. В каких случаях проще использовать ML-агент, а не писать программную реализацию решения?
Агента из 1 примера можно спользовать в играх, где игрока кто-то или что-то постоянно приследует. Мобы будут следовать за игроком, независимо от его координат. Если же на игровом поле будет не только игрок, но и дополнительные болоки которые можно обходить, то это добавит перед мобами задачу добраться до игрока самым оптимальным способом
Примером таких игр могут быть игры Brotato, Isec или любые игры, где игроку дается помощник на время какой-то миссии, который будет следовать за вами(пример - игра Ведьмак)
![11](https://github.com/user-attachments/assets/d0322729-9847-4c1f-97d2-9599fb19f52f)
![22](https://github.com/user-attachments/assets/e43fc710-88b9-45b5-b666-db5a8e2b8675)

Мне кажется, что оптимально использовать MI-агентов в играх, где перед игроковв повляется множество возможностей для передвежения, каких-то построек или иных взаиможействий с открытым миром, потому что для анализа окружения и учета каких-то событий вручную нужно будет создать слишком много переменных, нужно многое учитывать и легко допустить ошибку, которая приведет к багу. Ну  и конечно вручную прописывать скрипт будет очень очень долго.
Пример игры - Майнкрафт
## Выводы

Мы познакомилимь с программными средствами для создания системы машинного обучения и ее интеграции в Юнити
Проекты Unity и скриншот TensorBoard представлены на диске: https://drive.google.com/drive/folders/15kPFhwJ-NMjwTNzJdAxNcoM9lAJZpa6T?usp=sharing

## Powered by

**Dokira**
